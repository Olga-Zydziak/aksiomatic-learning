{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb06d35b-4e9c-40c8-afbc-c6daa6ca8461",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyyaml in /opt/conda/envs/graph-memory/lib/python3.12/site-packages (6.0.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pyyaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94e4ea63-8ac0-42af-9cc6-8a4127e5342e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import yaml\n",
    "\n",
    "from src.axiomatic_kernel import (\n",
    "    AxiomKernel,\n",
    "    VariableSchema,\n",
    "    AxiomDefinition,\n",
    "    DecisionLogger,\n",
    ")\n",
    "from src.nl_rule_parser import (\n",
    "    build_axiom_from_nl,\n",
    "    RuleParseError,\n",
    ")\n",
    "from src.explanation_engine import (\n",
    "    DecisionExplainer,\n",
    "    ExplanationConfig,\n",
    ")\n",
    "from src.rules_io import load_ruleset_from_file, apply_ruleset_to_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e17b721-4a56-4325-828a-379097b09192",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìò Wczytano ruleset: fraud_rules_v1 (v1.0.0)\n",
      "Opis: Podstawowe regu≈Çy fraud / AML\n",
      "Liczba regu≈Ç w pliku (≈ÇƒÖcznie): 3\n",
      "\n",
      "üìä Podsumowanie ≈Çadowania regu≈Ç:\n",
      "- total_rules:   3\n",
      "- enabled_rules: 2\n",
      "- loaded_rules:  2\n",
      "- skipped_rules: 1\n",
      "- errors:        {}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# === 1) SCHEMA DOPASOWANA DO FRAUD_RULES (tylko typy obs≈Çugiwane przez kernel) ===\n",
    "schema = [\n",
    "    VariableSchema(\"amount\", \"int\", \"Kwota transakcji w jednostkach minimalnych.\"),\n",
    "    VariableSchema(\"tx_count_24h\", \"int\", \"Liczba transakcji w ostatnich 24h.\"),\n",
    "    VariableSchema(\"is_pep\", \"bool\", \"Czy klient jest PEP.\"),\n",
    "    VariableSchema(\"is_suspicious\", \"bool\", \"Czy transakcja jest podejrzana.\"),\n",
    "]\n",
    "\n",
    "logger = DecisionLogger(\"logs/fraud_rules_demo.jsonl\")\n",
    "\n",
    "kernel = AxiomKernel(\n",
    "    schema=schema,\n",
    "    decision_variable=\"is_suspicious\",\n",
    "    logger=logger,\n",
    "    rule_version=\"fraud_rules_v1\",\n",
    ")\n",
    "\n",
    "# === 2) Wczytanie rulesetu z pliku YAML ===\n",
    "rules_path = Path(\"rules\") / \"fraud_rules_v1.yaml\"\n",
    "rules_path.parent.mkdir(exist_ok=True)\n",
    "\n",
    "ruleset = load_ruleset_from_file(rules_path)\n",
    "\n",
    "print(f\"üìò Wczytano ruleset: {ruleset.ruleset_id} (v{ruleset.version})\")\n",
    "print(f\"Opis: {ruleset.description}\")\n",
    "print(f\"Liczba regu≈Ç w pliku (≈ÇƒÖcznie): {len(ruleset.rules)}\")\n",
    "\n",
    "# === 3) Na≈Ço≈ºenie rulesetu na kernel ===\n",
    "summary = apply_ruleset_to_kernel(\n",
    "    kernel=kernel,\n",
    "    ruleset=ruleset,\n",
    "    schema=schema,                         # üëà NOWE: przekazujemy schema\n",
    "    decision_field_fallback=\"is_suspicious\",  # üëà NOWE: ta sama zmienna co decision_variable\n",
    "    strict=True,                           # przerwij przy pierwszym b≈Çƒôdzie\n",
    "    extra_metadata={\"domain\": \"fraud-demo\"},\n",
    ")\n",
    "\n",
    "print(\"\\nüìä Podsumowanie ≈Çadowania regu≈Ç:\")\n",
    "print(f\"- total_rules:   {summary.total_rules}\")\n",
    "print(f\"- enabled_rules: {summary.enabled_rules}\")\n",
    "print(f\"- loaded_rules:  {summary.loaded_rules}\")\n",
    "print(f\"- skipped_rules: {summary.skipped_rules}\")\n",
    "print(f\"- errors:        {summary.errors}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704f5e2f-4e82-4fb5-af63-ab3bae7fd941",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Katalog i plik z regu≈Çami dla tego notebooka\n",
    "rules_dir = Path(\"rules\")\n",
    "rules_dir.mkdir(exist_ok=True)\n",
    "\n",
    "rules_file = rules_dir / \"notebook_rules.yaml\"\n",
    "\n",
    "# Domy≈õlny zestaw regu≈Ç ‚Äì u≈ºyty tylko, je≈õli plik nie istnieje.\n",
    "default_rules_yaml = \"\"\"rules:\n",
    "  - id: \"nl_high_risk_flag\"\n",
    "    text: \"If amount > 10000 and risk_score > 5 then flag = true\"\n",
    "  - id: \"nl_low_risk_clear\"\n",
    "    text: \"If risk_score <= 2 then flag = false\"\n",
    "\"\"\"\n",
    "\n",
    "if not rules_file.exists():\n",
    "    rules_file.write_text(default_rules_yaml, encoding=\"utf-8\")\n",
    "    print(f\"Utworzono domy≈õlny plik z regu≈Çami: {rules_file}\")\n",
    "else:\n",
    "    print(f\"U≈ºywam istniejƒÖcego pliku z regu≈Çami: {rules_file}\")\n",
    "\n",
    "# Wczytanie regu≈Ç z pliku YAML\n",
    "with rules_file.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    rules_data = yaml.safe_load(f)\n",
    "\n",
    "rules_list = rules_data.get(\"rules\", [])\n",
    "\n",
    "axioms = []\n",
    "for raw_rule in rules_list:\n",
    "    rule_id = raw_rule[\"id\"]\n",
    "    text = raw_rule[\"text\"]\n",
    "\n",
    "    axiom = build_axiom_from_nl(\n",
    "        rule_id=rule_id,\n",
    "        text=text,\n",
    "        schema=schema,\n",
    "        decision_field_fallback=\"flag\",\n",
    "    )\n",
    "    kernel.add_axiom_safe(axiom)\n",
    "    axioms.append(axiom)\n",
    "\n",
    "print(\"Dodane regu≈Çy:\", [a.id for a in axioms])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ce764e5-b449-4f88-ac13-035ab1270a60",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RAW BUNDLE (FLAGGED) ===\n",
      "{\n",
      "  \"decision_status\": \"SAT\",\n",
      "  \"decision\": \"FLAGGED\",\n",
      "  \"facts\": {\n",
      "    \"amount\": 15000\n",
      "  },\n",
      "  \"model\": {\n",
      "    \"amount\": 15000,\n",
      "    \"tx_count_24h\": 0,\n",
      "    \"is_pep\": false,\n",
      "    \"is_suspicious\": true\n",
      "  },\n",
      "  \"satisfied_axioms\": [\n",
      "    {\n",
      "      \"id\": \"fraud.high_amount\",\n",
      "      \"description\": \"IF amount > 10000 THEN is_suspicious = TRUE\",\n",
      "      \"holds\": true,\n",
      "      \"antecedent_true\": true\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"fraud.velocity\",\n",
      "      \"description\": \"IF tx_count_24h > 5 THEN is_suspicious = TRUE\",\n",
      "      \"holds\": true,\n",
      "      \"antecedent_true\": false\n",
      "    }\n",
      "  ],\n",
      "  \"violated_axioms\": [],\n",
      "  \"active_axioms\": [\n",
      "    {\n",
      "      \"id\": \"fraud.high_amount\",\n",
      "      \"description\": \"IF amount > 10000 THEN is_suspicious = TRUE\",\n",
      "      \"holds\": true,\n",
      "      \"antecedent_true\": true\n",
      "    }\n",
      "  ],\n",
      "  \"inactive_actions\": [\n",
      "    {\n",
      "      \"id\": \"fraud.velocity\",\n",
      "      \"description\": \"IF tx_count_24h > 5 THEN is_suspicious = TRUE\",\n",
      "      \"holds\": true,\n",
      "      \"antecedent_true\": false\n",
      "    }\n",
      "  ],\n",
      "  \"conflicting_axioms\": [],\n",
      "  \"rule_version\": \"fraud_rules_v1\",\n",
      "  \"decision_id\": \"fa790b40-1bf8-4f90-92c0-93c877ef9751\",\n",
      "  \"logged_at_utc\": \"2025-12-01T22:47:47.873833\"\n",
      "}\n",
      "\n",
      "=== WYJA≈öNIENIE (FLAGGED) ===\n",
      "Decyzja: transakcja zosta≈Ça OFLAGOWANA (FLAGGED). Kluczowe dane wej≈õciowe: amount=15000.\n",
      "\n",
      "Powody (aktywne regu≈Çy):\n",
      "- Regu≈Ça 'fraud.high_amount': IF amount > 10000 THEN is_suspicious = TRUE\n",
      "\n",
      "Regu≈Çy, kt√≥re nie zadzia≈Ça≈Çy w tym przypadku:\n",
      "- Regu≈Ça 'fraud.velocity' by≈Ça spe≈Çniona logicznie, ale jej warunek nie dotyczy≈Ç tego przypadku: IF tx_count_24h > 5 THEN is_suspicious = TRUE\n",
      "=== RAW BUNDLE (CLEAN) ===\n",
      "{\n",
      "  \"decision_status\": \"SAT\",\n",
      "  \"decision\": \"FLAGGED\",\n",
      "  \"facts\": {\n",
      "    \"amount\": 500\n",
      "  },\n",
      "  \"model\": {\n",
      "    \"amount\": 500,\n",
      "    \"tx_count_24h\": 0,\n",
      "    \"is_pep\": false,\n",
      "    \"is_suspicious\": true\n",
      "  },\n",
      "  \"satisfied_axioms\": [\n",
      "    {\n",
      "      \"id\": \"fraud.high_amount\",\n",
      "      \"description\": \"IF amount > 10000 THEN is_suspicious = TRUE\",\n",
      "      \"holds\": true,\n",
      "      \"antecedent_true\": false\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"fraud.velocity\",\n",
      "      \"description\": \"IF tx_count_24h > 5 THEN is_suspicious = TRUE\",\n",
      "      \"holds\": true,\n",
      "      \"antecedent_true\": false\n",
      "    }\n",
      "  ],\n",
      "  \"violated_axioms\": [],\n",
      "  \"active_axioms\": [],\n",
      "  \"inactive_actions\": [\n",
      "    {\n",
      "      \"id\": \"fraud.high_amount\",\n",
      "      \"description\": \"IF amount > 10000 THEN is_suspicious = TRUE\",\n",
      "      \"holds\": true,\n",
      "      \"antecedent_true\": false\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"fraud.velocity\",\n",
      "      \"description\": \"IF tx_count_24h > 5 THEN is_suspicious = TRUE\",\n",
      "      \"holds\": true,\n",
      "      \"antecedent_true\": false\n",
      "    }\n",
      "  ],\n",
      "  \"conflicting_axioms\": [],\n",
      "  \"rule_version\": \"fraud_rules_v1\",\n",
      "  \"decision_id\": \"90db8a91-800d-4620-8fcf-911dac162eb1\",\n",
      "  \"logged_at_utc\": \"2025-12-01T22:47:47.877611\"\n",
      "}\n",
      "\n",
      "=== WYJA≈öNIENIE (CLEAN) ===\n",
      "Decyzja: transakcja zosta≈Ça OFLAGOWANA (FLAGGED). Kluczowe dane wej≈õciowe: amount=500.\n",
      "\n",
      "Regu≈Çy, kt√≥re nie zadzia≈Ça≈Çy w tym przypadku:\n",
      "- Regu≈Ça 'fraud.high_amount' by≈Ça spe≈Çniona logicznie, ale jej warunek nie dotyczy≈Ç tego przypadku: IF amount > 10000 THEN is_suspicious = TRUE\n",
      "- Regu≈Ça 'fraud.velocity' by≈Ça spe≈Çniona logicznie, ale jej warunek nie dotyczy≈Ç tego przypadku: IF tx_count_24h > 5 THEN is_suspicious = TRUE\n"
     ]
    }
   ],
   "source": [
    "explainer = DecisionExplainer(ExplanationConfig(language=\"pl\"))\n",
    "\n",
    "# Przypadek wysokiego ryzyka ‚Äì powinno byƒá FLAGGED\n",
    "case_flagged = {\"amount\": 15_000, \"risk_score\": 7}\n",
    "bundle_flagged = kernel.evaluate(case_flagged)\n",
    "\n",
    "print(\"=== RAW BUNDLE (FLAGGED) ===\")\n",
    "print(json.dumps(bundle_flagged, indent=2, ensure_ascii=False))\n",
    "\n",
    "print(\"\\n=== WYJA≈öNIENIE (FLAGGED) ===\")\n",
    "print(explainer.explain(bundle_flagged).to_text(language=\"pl\"))\n",
    "\n",
    "\n",
    "\n",
    "# Przypadek niskiego ryzyka ‚Äì powinno byƒá CLEAN\n",
    "case_clean = {\"amount\": 500, \"risk_score\": 1}\n",
    "bundle_clean = kernel.evaluate(case_clean)\n",
    "\n",
    "print(\"=== RAW BUNDLE (CLEAN) ===\")\n",
    "print(json.dumps(bundle_clean, indent=2, ensure_ascii=False))\n",
    "\n",
    "print(\"\\n=== WYJA≈öNIENIE (CLEAN) ===\")\n",
    "print(explainer.explain(bundle_clean).to_text(language=\"pl\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06cf18c8-5d80-40b2-89e9-e57f765764b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Kernel evaluation error\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter/olga_zydziak/version_beta/Folder/casual_model/Axiomatic-learning/src/axiomatic_kernel.py\", line 375, in evaluate\n",
      "    constraint = axiom.build_constraint(self._variables)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/tmp/ipykernel_17759/431343928.py\", line 12, in rule_flag_true\n",
      "    flag = vars_z3[\"flag\"]\n",
      "           ~~~~~~~^^^^^^^^\n",
      "KeyError: 'flag'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RAW BUNDLE (UNSAT) ===\n",
      "{\n",
      "  \"decision_status\": \"ERROR\",\n",
      "  \"decision\": \"ERROR\",\n",
      "  \"facts\": {\n",
      "    \"amount\": 15000,\n",
      "    \"risk_score\": 5\n",
      "  },\n",
      "  \"model\": {},\n",
      "  \"satisfied_axioms\": [],\n",
      "  \"violated_axioms\": [],\n",
      "  \"active_axioms\": [],\n",
      "  \"inactive_actions\": [],\n",
      "  \"conflicting_axioms\": [],\n",
      "  \"rule_version\": \"demo_unsat_v1\",\n",
      "  \"error\": \"'flag'\"\n",
      "}\n",
      "\n",
      "=== WYJA≈öNIENIE (UNSAT) ===\n",
      "WystƒÖpi≈Ç b≈ÇƒÖd podczas ewaluacji regu≈Ç. Kluczowe dane wej≈õciowe: amount=15000, risk_score=5.\n",
      "\n",
      "B≈ÇƒÖd techniczny: 'flag'\n"
     ]
    }
   ],
   "source": [
    "from z3 import Implies  # type: ignore\n",
    "\n",
    "unsat_kernel = AxiomKernel(\n",
    "    schema=schema,\n",
    "    decision_variable=\"flag\",\n",
    "    logger=None,\n",
    "    rule_version=\"demo_unsat_v1\",\n",
    ")\n",
    "\n",
    "def rule_flag_true(vars_z3):\n",
    "    amount = vars_z3[\"amount\"]\n",
    "    flag = vars_z3[\"flag\"]\n",
    "    return Implies(amount > 10_000, flag == True)\n",
    "\n",
    "def rule_flag_false(vars_z3):\n",
    "    amount = vars_z3[\"amount\"]\n",
    "    flag = vars_z3[\"flag\"]\n",
    "    return Implies(amount > 10_000, flag == False)\n",
    "\n",
    "unsat_kernel.add_axiom(\n",
    "    AxiomDefinition(\n",
    "        id=\"amount_flag_true\",\n",
    "        description=\"If amount > 10000 then flag must be True.\",\n",
    "        build_constraint=rule_flag_true,\n",
    "    )\n",
    ")\n",
    "unsat_kernel.add_axiom(\n",
    "    AxiomDefinition(\n",
    "        id=\"amount_flag_false\",\n",
    "        description=\"If amount > 10000 then flag must be False.\",\n",
    "        build_constraint=rule_flag_false,\n",
    "    )\n",
    ")\n",
    "\n",
    "case_conflict = {\"amount\": 15_000, \"risk_score\": 5}\n",
    "bundle_unsat = unsat_kernel.evaluate(case_conflict)\n",
    "\n",
    "print(\"=== RAW BUNDLE (UNSAT) ===\")\n",
    "print(json.dumps(bundle_unsat, indent=2, ensure_ascii=False))\n",
    "\n",
    "print(\"\\n=== WYJA≈öNIENIE (UNSAT) ===\")\n",
    "print(explainer.explain(bundle_unsat).to_text(language=\"pl\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec462348-ee33-47d7-8363-d6f99c14d3c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\"\"\"rule_analytics.py\n",
    "\n",
    "FAZA 4 ‚Äì Silnik analizy regu≈Ç i decyzji na podstawie log√≥w JSONL\n",
    "generowanych przez DecisionLogger z axiomatic_kernel.py.\n",
    "\n",
    "G≈Ç√≥wne za≈Ço≈ºenia:\n",
    "- ≈πr√≥d≈Çem prawdy sƒÖ logi decyzji (JSONL), gdzie ka≈ºda linia ma postaƒá:\n",
    "    {\n",
    "      \"decision_id\": \"<uuid>\",\n",
    "      \"logged_at_utc\": \"<ISO timestamp>\",\n",
    "      \"decision\": {\n",
    "         \"decision_status\": \"...\",\n",
    "         \"decision\": \"...\",\n",
    "         \"facts\": {...},\n",
    "         \"model\": {...},\n",
    "         \"satisfied_axioms\": [...],\n",
    "         \"violated_axioms\": [...],\n",
    "         \"active_axioms\": [...],\n",
    "         \"inactive_actions\": [...],\n",
    "         \"conflicting_axioms\": [...],\n",
    "         \"rule_version\": \"...\"\n",
    "         ...\n",
    "      }\n",
    "    }\n",
    "\n",
    "- Modu≈Ç nie zale≈ºy od Z3 ani innych ciƒô≈ºkich komponent√≥w ‚Äì operuje\n",
    "  wy≈ÇƒÖcznie na danych z log√≥w.\n",
    "\n",
    "- Wynikiem analizy jest struktura danych gotowa do dalszego\n",
    "  raportowania / wizualizacji w PoC bankowym:\n",
    "  * statystyki decyzji,\n",
    "  * statystyki regu≈Ç,\n",
    "  * raport pokrycia rulesetu (je≈õli podamy RuleSet z rules_io).\n",
    "\n",
    "Mo≈ºesz ten modu≈Ç wpiƒÖƒá bezpo≈õrednio do istniejƒÖcego projektu.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import logging\n",
    "from dataclasses import dataclass, field\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, Iterable, List, Optional\n",
    "\n",
    "from rules_io import RuleSet, load_ruleset_from_file\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Modele danych\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DecisionRecord:\n",
    "    \"\"\"Pojedynczy rekord decyzji odczytany z logu JSONL.\n",
    "\n",
    "    Attributes:\n",
    "        decision_id:\n",
    "            Identyfikator decyzji nadany przez DecisionLogger.\n",
    "        logged_at_utc:\n",
    "            Moment zapisania decyzji w formacie datetime (UTC).\n",
    "        bundle:\n",
    "            Pe≈Çny \"proof bundle\" zwr√≥cony przez AxiomKernel.evaluate().\n",
    "    \"\"\"\n",
    "\n",
    "    decision_id: str\n",
    "    logged_at_utc: datetime\n",
    "    bundle: Dict[str, Any]\n",
    "\n",
    "    @staticmethod\n",
    "    def from_json_line(line: str) -> \"DecisionRecord\":\n",
    "        \"\"\"Parsuje jednƒÖ liniƒô JSONL i zwraca DecisionRecord.\n",
    "\n",
    "        Podnosi ValueError przy b≈Çƒôdnym formacie.\n",
    "        \"\"\"\n",
    "        raw = json.loads(line)\n",
    "        decision_id = str(raw.get(\"decision_id\", \"\"))\n",
    "\n",
    "        logged_at_raw = raw.get(\"logged_at_utc\")\n",
    "        if not isinstance(logged_at_raw, str):\n",
    "            raise ValueError(\"logged_at_utc must be a string timestamp\")\n",
    "\n",
    "        try:\n",
    "            logged_at = datetime.fromisoformat(logged_at_raw)\n",
    "        except ValueError as exc:\n",
    "            raise ValueError(\n",
    "                f\"Invalid ISO timestamp in logged_at_utc: {logged_at_raw!r}\"\n",
    "            ) from exc\n",
    "\n",
    "        bundle = raw.get(\"decision\")\n",
    "        if not isinstance(bundle, dict):\n",
    "            raise ValueError(\"'decision' field must be an object\")\n",
    "\n",
    "        return DecisionRecord(\n",
    "            decision_id=decision_id or \"\",\n",
    "            logged_at_utc=logged_at,\n",
    "            bundle=bundle,\n",
    "        )\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DecisionOutcomeStats:\n",
    "    \"\"\"Zagregowane statystyki decyzji w logu.\"\"\"\n",
    "\n",
    "    total_decisions: int = 0\n",
    "    by_decision: Dict[str, int] = field(default_factory=dict)\n",
    "    by_status: Dict[str, int] = field(default_factory=dict)\n",
    "    by_rule_version: Dict[str, int] = field(default_factory=dict)\n",
    "\n",
    "    # liczba przypadk√≥w, w kt√≥rych solver zwr√≥ci≈Ç UNSAT (konflikt regu≈Ç)\n",
    "    unsat_cases: int = 0\n",
    "\n",
    "    # liczba przypadk√≥w, w kt√≥rych status by≈Ç ERROR lub UNKNOWN\n",
    "    error_cases: int = 0\n",
    "\n",
    "    def as_dict(self) -> Dict[str, Any]:\n",
    "        return {\n",
    "            \"total_decisions\": self.total_decisions,\n",
    "            \"by_decision\": dict(self.by_decision),\n",
    "            \"by_status\": dict(self.by_status),\n",
    "            \"by_rule_version\": dict(self.by_rule_version),\n",
    "            \"unsat_cases\": self.unsat_cases,\n",
    "            \"error_cases\": self.error_cases,\n",
    "        }\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class RuleStats:\n",
    "    \"\"\"Statystyki pojedynczej regu≈Çy (na przestrzeni wielu decyzji).\"\"\"\n",
    "\n",
    "    rule_id: str\n",
    "    description: Optional[str] = None\n",
    "\n",
    "    # liczba decyzji, w kt√≥rych regu≈Ça w og√≥le siƒô pojawi≈Ça\n",
    "    total_occurrences: int = 0\n",
    "\n",
    "    # liczba decyzji, w kt√≥rych regu≈Ça by≈Ça logicznie spe≈Çniona\n",
    "    satisfied: int = 0\n",
    "\n",
    "    # liczba decyzji, w kt√≥rych regu≈Ça by≈Ça logicznie niespe≈Çniona\n",
    "    violated: int = 0\n",
    "\n",
    "    # liczba decyzji, w kt√≥rych antecedent by≈Ç TRUE\n",
    "    active: int = 0\n",
    "\n",
    "    # liczba decyzji, w kt√≥rych regu≈Ça by≈Ça true \"vacuously\" (antecedent FALSE)\n",
    "    inactive: int = 0\n",
    "\n",
    "    # liczba decyzji, w kt√≥rych regu≈Ça wystƒÖpi≈Ça w conflicting_axioms\n",
    "    in_conflict: int = 0\n",
    "\n",
    "    def as_dict(self) -> Dict[str, Any]:\n",
    "        return {\n",
    "            \"rule_id\": self.rule_id,\n",
    "            \"description\": self.description,\n",
    "            \"total_occurrences\": self.total_occurrences,\n",
    "            \"satisfied\": self.satisfied,\n",
    "            \"violated\": self.violated,\n",
    "            \"active\": self.active,\n",
    "            \"inactive\": self.inactive,\n",
    "            \"in_conflict\": self.in_conflict,\n",
    "        }\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class RuleCoverageReport:\n",
    "    \"\"\"Raport pokrycia rulesetu na podstawie log√≥w.\n",
    "\n",
    "    Attributes:\n",
    "        ruleset_id:\n",
    "            Id rulesetu (z pliku).\n",
    "        version:\n",
    "            Wersja rulesetu.\n",
    "        total_enabled_rules:\n",
    "            Liczba regu≈Ç enabled=True w ruleset.\n",
    "        used_rules:\n",
    "            Lista identyfikator√≥w regu≈Ç, kt√≥re pojawi≈Çy siƒô\n",
    "            w statystykach (czyli wystƒÖpi≈Çy w co najmniej jednej decyzji).\n",
    "        unused_rules:\n",
    "            Lista identyfikator√≥w regu≈Ç enabled=True, kt√≥re nie\n",
    "            pojawi≈Çy siƒô w logach (martwe / nieu≈ºywane).\n",
    "    \"\"\"\n",
    "\n",
    "    ruleset_id: str\n",
    "    version: str\n",
    "    total_enabled_rules: int\n",
    "    used_rules: List[str] = field(default_factory=list)\n",
    "    unused_rules: List[str] = field(default_factory=list)\n",
    "\n",
    "    def as_dict(self) -> Dict[str, Any]:\n",
    "        return {\n",
    "            \"ruleset_id\": self.ruleset_id,\n",
    "            \"version\": self.version,\n",
    "            \"total_enabled_rules\": self.total_enabled_rules,\n",
    "            \"used_rules\": list(self.used_rules),\n",
    "            \"unused_rules\": list(self.unused_rules),\n",
    "        }\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class RuleAnalyticsResult:\n",
    "    \"\"\"Kompletny wynik analizy regu≈Ç i decyzji.\"\"\"\n",
    "\n",
    "    outcome_stats: DecisionOutcomeStats\n",
    "    rule_stats: Dict[str, RuleStats] = field(default_factory=dict)\n",
    "    coverage_report: Optional[RuleCoverageReport] = None\n",
    "\n",
    "    def as_dict(self) -> Dict[str, Any]:\n",
    "        return {\n",
    "            \"outcome_stats\": self.outcome_stats.as_dict(),\n",
    "            \"rule_stats\": {\n",
    "                rule_id: stats.as_dict()\n",
    "                for rule_id, stats in sorted(self.rule_stats.items())\n",
    "            },\n",
    "            \"coverage_report\": (\n",
    "                None\n",
    "                if self.coverage_report is None\n",
    "                else self.coverage_report.as_dict()\n",
    "            ),\n",
    "        }\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Czytnik log√≥w JSONL\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "class DecisionLogReader:\n",
    "    \"\"\"Prosty reader log√≥w JSONL z DecisionLogger.\n",
    "\n",
    "    Przechodzi liniƒô po linii, zwraca DecisionRecord. B≈Çƒôdy parsowania\n",
    "    loguje, ale nie przerywa ca≈Çej analizy (odrzuca wadliwƒÖ liniƒô).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, path: str | Path) -> None:\n",
    "        self._path = Path(path)\n",
    "\n",
    "    def iter_decisions(self) -> Iterable[DecisionRecord]:\n",
    "        if not self._path.exists():\n",
    "            logger.warning(\n",
    "                \"Decision log file %s does not exist ‚Äì no data to analyze.\",\n",
    "                self._path,\n",
    "            )\n",
    "            return\n",
    "\n",
    "        with self._path.open(\"r\", encoding=\"utf-8\") as file:\n",
    "            for line_number, line in enumerate(file, start=1):\n",
    "                stripped = line.strip()\n",
    "                if not stripped:\n",
    "                    continue\n",
    "                try:\n",
    "                    yield DecisionRecord.from_json_line(stripped)\n",
    "                except Exception:  # pragma: no cover - defensywne logowanie\n",
    "                    logger.exception(\n",
    "                        \"Failed to parse decision log line %d in %s\",\n",
    "                        line_number,\n",
    "                        self._path,\n",
    "                    )\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Silnik analityczny\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "class RuleAnalyticsEngine:\n",
    "    \"\"\"G≈Ç√≥wny silnik analizy log√≥w regu≈Çowych.\n",
    "\n",
    "    Typowe u≈ºycie:\n",
    "\n",
    "        engine = RuleAnalyticsEngine()\n",
    "        result = engine.analyze_log_file(\n",
    "            log_path=\"decision_log.jsonl\",\n",
    "            ruleset_path=\"rules_aml_v1.yaml\",\n",
    "        )\n",
    "        report = result.as_dict()\n",
    "    \"\"\"\n",
    "\n",
    "    def analyze_log_file(\n",
    "        self,\n",
    "        *,\n",
    "        log_path: str | Path,\n",
    "        ruleset: Optional[RuleSet] = None,\n",
    "        ruleset_path: Optional[str | Path] = None,\n",
    "    ) -> RuleAnalyticsResult:\n",
    "        \"\"\"Analizuje podany plik log√≥w JSONL.\n",
    "\n",
    "        Mo≈ºesz przekazaƒá:\n",
    "        - gotowy RuleSet (ruleset),\n",
    "        - albo ≈õcie≈ºkƒô do pliku rulesetu (ruleset_path),\n",
    "        - albo nic (analiza tylko decyzji i regu≈Ç obecnych w logach).\n",
    "\n",
    "        Je≈õli podano zar√≥wno ruleset, jak i ruleset_path, priorytet\n",
    "        ma obiekt ruleset.\n",
    "        \"\"\"\n",
    "\n",
    "        if ruleset is None and ruleset_path is not None:\n",
    "            ruleset = load_ruleset_from_file(Path(ruleset_path))\n",
    "\n",
    "        reader = DecisionLogReader(log_path)\n",
    "\n",
    "        outcome_stats = DecisionOutcomeStats()\n",
    "        rule_stats: Dict[str, RuleStats] = {}\n",
    "\n",
    "        for record in reader.iter_decisions():\n",
    "            bundle = record.bundle\n",
    "\n",
    "            decision = str(bundle.get(\"decision\", \"UNKNOWN\"))\n",
    "            status = str(bundle.get(\"decision_status\", \"UNKNOWN\"))\n",
    "            rule_version = str(bundle.get(\"rule_version\", \"unknown\"))\n",
    "\n",
    "            outcome_stats.total_decisions += 1\n",
    "            outcome_stats.by_decision[decision] = (\n",
    "                outcome_stats.by_decision.get(decision, 0) + 1\n",
    "            )\n",
    "            outcome_stats.by_status[status] = (\n",
    "                outcome_stats.by_status.get(status, 0) + 1\n",
    "            )\n",
    "            outcome_stats.by_rule_version[rule_version] = (\n",
    "                outcome_stats.by_rule_version.get(rule_version, 0) + 1\n",
    "            )\n",
    "\n",
    "            if status == \"UNSAT\":\n",
    "                outcome_stats.unsat_cases += 1\n",
    "            if status in {\"ERROR\", \"UNKNOWN\"}:\n",
    "                outcome_stats.error_cases += 1\n",
    "\n",
    "            # Zbierz regu≈Çy wystƒôpujƒÖce w tej decyzji, aby m√≥c policzyƒá\n",
    "            # total_occurrences (ka≈ºda regu≈Ça max raz na decyzjƒô).\n",
    "            rules_in_decision: set[str] = set()\n",
    "\n",
    "            def _ensure_rule_stats(\n",
    "                rule_id: str,\n",
    "                description: Optional[str],\n",
    "            ) -> RuleStats:\n",
    "                if rule_id not in rule_stats:\n",
    "                    rule_stats[rule_id] = RuleStats(\n",
    "                        rule_id=rule_id,\n",
    "                        description=description,\n",
    "                    )\n",
    "                else:\n",
    "                    # Je≈õli wcze≈õniej description by≈Ço None, a teraz mamy\n",
    "                    # jakikolwiek opis, uzupe≈Çnijmy go.\n",
    "                    if description and not rule_stats[rule_id].description:\n",
    "                        rule_stats[rule_id].description = description\n",
    "                return rule_stats[rule_id]\n",
    "\n",
    "            # satisfied_axioms: lista dict√≥w z polami id, description, ...\n",
    "            for entry in bundle.get(\"satisfied_axioms\", []):\n",
    "                rule_id = str(entry.get(\"id\", \"\"))\n",
    "                if not rule_id:\n",
    "                    continue\n",
    "                description = entry.get(\"description\")\n",
    "                stats = _ensure_rule_stats(rule_id, description)\n",
    "                stats.satisfied += 1\n",
    "                rules_in_decision.add(rule_id)\n",
    "\n",
    "            # violated_axioms\n",
    "            for entry in bundle.get(\"violated_axioms\", []):\n",
    "                rule_id = str(entry.get(\"id\", \"\"))\n",
    "                if not rule_id:\n",
    "                    continue\n",
    "                description = entry.get(\"description\")\n",
    "                stats = _ensure_rule_stats(rule_id, description)\n",
    "                stats.violated += 1\n",
    "                rules_in_decision.add(rule_id)\n",
    "\n",
    "            # active_axioms\n",
    "            for entry in bundle.get(\"active_axioms\", []):\n",
    "                rule_id = str(entry.get(\"id\", \"\"))\n",
    "                if not rule_id:\n",
    "                    continue\n",
    "                description = entry.get(\"description\")\n",
    "                stats = _ensure_rule_stats(rule_id, description)\n",
    "                stats.active += 1\n",
    "                rules_in_decision.add(rule_id)\n",
    "\n",
    "            # inactive_actions\n",
    "            for entry in bundle.get(\"inactive_actions\", []):\n",
    "                rule_id = str(entry.get(\"id\", \"\"))\n",
    "                if not rule_id:\n",
    "                    continue\n",
    "                description = entry.get(\"description\")\n",
    "                stats = _ensure_rule_stats(rule_id, description)\n",
    "                stats.inactive += 1\n",
    "                rules_in_decision.add(rule_id)\n",
    "\n",
    "            # conflicting_axioms: lista id (string√≥w)\n",
    "            for rule_id in bundle.get(\"conflicting_axioms\", []):\n",
    "                rule_id_str = str(rule_id)\n",
    "                if not rule_id_str:\n",
    "                    continue\n",
    "                stats = _ensure_rule_stats(rule_id_str, None)\n",
    "                stats.in_conflict += 1\n",
    "                rules_in_decision.add(rule_id_str)\n",
    "\n",
    "            # Na koniec zwiƒôkszamy total_occurrences dla ka≈ºdej regu≈Çy,\n",
    "            # kt√≥ra pojawi≈Ça siƒô w tej decyzji w jakiejkolwiek roli.\n",
    "            for rule_id in rules_in_decision:\n",
    "                rule_stats[rule_id].total_occurrences += 1\n",
    "\n",
    "        coverage_report: Optional[RuleCoverageReport] = None\n",
    "\n",
    "        if ruleset is not None:\n",
    "            # Identyfikatory regu≈Ç, kt√≥re wystƒôpujƒÖ w statystykach\n",
    "            used_rule_ids = {rule_id for rule_id in rule_stats}\n",
    "            enabled_rules = [rule for rule in ruleset.rules if rule.enabled]\n",
    "            enabled_rule_ids = {rule.rule_id for rule in enabled_rules}\n",
    "            unused_rule_ids = sorted(enabled_rule_ids - used_rule_ids)\n",
    "            used_rule_ids_sorted = sorted(enabled_rule_ids & used_rule_ids)\n",
    "\n",
    "            coverage_report = RuleCoverageReport(\n",
    "                ruleset_id=ruleset.ruleset_id,\n",
    "                version=ruleset.version,\n",
    "                total_enabled_rules=len(enabled_rules),\n",
    "                used_rules=used_rule_ids_sorted,\n",
    "                unused_rules=unused_rule_ids,\n",
    "            )\n",
    "\n",
    "        return RuleAnalyticsResult(\n",
    "            outcome_stats=outcome_stats,\n",
    "            rule_stats=rule_stats,\n",
    "            coverage_report=coverage_report,\n",
    "        )\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "workbench-notebooks.m129",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m129"
  },
  "kernelspec": {
   "display_name": "Graph-memory (Python=3.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}